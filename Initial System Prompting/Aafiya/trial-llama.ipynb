{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/aafiyahussain/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-19 21:32:42,850\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import *\n",
    "import pandas as pd\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=512,temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-19 21:32:45 __init__.py:207] Automatically detected platform cuda.\n",
      "INFO 04-19 21:32:56 config.py:549] This model supports multiple tasks: {'score', 'embed', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 04-19 21:32:56 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 04-19 21:32:57 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 04-19 21:32:58 model_runner.py:1110] Starting to load model meta-llama/Llama-3.1-8B-Instruct...\n",
      "INFO 04-19 21:32:58 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
      "INFO 04-19 21:39:08 weight_utils.py:270] Time spent downloading weights for meta-llama/Llama-3.1-8B-Instruct: 369.794845 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:10<00:30, 10.16s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:53<00:59, 29.66s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:37<00:36, 36.02s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:20<00:00, 38.89s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:20<00:00, 35.09s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-19 21:41:30 model_runner.py:1115] Loading model weights took 14.9888 GB\n",
      "INFO 04-19 21:41:31 worker.py:267] Memory profiling takes 1.40 seconds\n",
      "INFO 04-19 21:41:31 worker.py:267] the current vLLM instance can use total_gpu_memory (44.43GiB) x gpu_memory_utilization (0.90) = 39.99GiB\n",
      "INFO 04-19 21:41:31 worker.py:267] model weights take 14.99GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 23.71GiB.\n",
      "INFO 04-19 21:41:31 executor_base.py:111] # cuda blocks: 12139, # CPU blocks: 2048\n",
      "INFO 04-19 21:41:31 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 23.71x\n",
      "INFO 04-19 21:41:33 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:14<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-19 21:41:48 model_runner.py:1562] Graph capturing finished in 14 secs, took 0.26 GiB\n",
      "INFO 04-19 21:41:48 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 18.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llm = LLM(\n",
    "    model=model_id,\n",
    "    tensor_parallel_size=1,\n",
    "    max_model_len=8192\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(summary_statistics,sampled_rows):\n",
    "    prompt = f\"\"\"You are a data visualization expert whose goal is to suggest most insighful visualization from a list of options.  \n",
    "    You will be provided with two inputs:\n",
    "\n",
    "    1. **Summary statistics** (the comma seperated output of `df.describe()`)  \n",
    "    2. **Ten sample rows** from the dataset, each row on its own line, with comma‑separated values.\n",
    "\n",
    "    Your task is to:\n",
    "\n",
    "    1. Choose **one** visualization from this list of common exploratory plots:\n",
    "    - Histogram  \n",
    "    - Box plot  \n",
    "    - Scatter plot  \n",
    "    - Bar chart  \n",
    "    - Line chart  \n",
    "    - Heatmap (e.g. correlation matrix)  \n",
    "    - Pair plot (scatterplot matrix)  \n",
    "    - Violin plot  \n",
    "    - Density plot  \n",
    "    - Stacked bar chart  \n",
    "\n",
    "    2. Explain your **rationale** for selecting that visualization given the summary statistics and sample rows.\n",
    "\n",
    "    Inputs:\n",
    "    1. Summary statistics:\n",
    "    {summary_statistics}\n",
    "\n",
    "    2. Ten randomly selected rows from the dataset:\n",
    "    {sampled_rows}\n",
    "\n",
    "    Provide your answer in the format \\\\boxed{{answer}} at the end.\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stat_and_rows(df):\n",
    "    summary_statistics = df.describe().to_csv(index=True)\n",
    "    sampled_rows = df.sample(n=10, random_state=42).to_csv(index=False)\n",
    "    return summary_statistics,sampled_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['target'] = [iris.target_names[t] for t in iris.target]\n",
    "# csv_data = df_iris.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics, sampled_rows = get_summary_stat_and_rows(df_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_prompt(summary_statistics,sampled_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt='<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are a data visualization expert whose goal is to suggest most insighful visualization from a list of options.  \\n    You will be provided with two inputs:\\n\\n    1. **Summary statistics** (the comma seperated output of `df.describe()`)  \\n    2. **Ten sample rows** from the dataset, each row on its own line, with comma‑separated values.\\n\\n    Your task is to:\\n\\n    1. Choose **one** visualization from this list of common exploratory plots:\\n    - Histogram  \\n    - Box plot  \\n    - Scatter plot  \\n    - Bar chart  \\n    - Line chart  \\n    - Heatmap (e.g. correlation matrix)  \\n    - Pair plot (scatterplot matrix)  \\n    - Violin plot  \\n    - Density plot  \\n    - Stacked bar chart  \\n\\n    2. Explain your **rationale** for selecting that visualization given the summary statistics and sample rows.\\n\\n    Inputs:\\n    1. Summary statistics:\\n    ,sepal length (cm),sepal width (cm),petal length (cm),petal width (cm)\\ncount,150.0,150.0,150.0,150.0\\nmean,5.843333333333334,3.0573333333333337,3.7580000000000005,1.1993333333333336\\nstd,0.828066127977863,0.4358662849366982,1.7652982332594662,0.7622376689603465\\nmin,4.3,2.0,1.0,0.1\\n25%,5.1,2.8,1.6,0.3\\n50%,5.8,3.0,4.35,1.3\\n75%,6.4,3.3,5.1,1.8\\nmax,7.9,4.4,6.9,2.5\\n\\n\\n    2. Ten randomly selected rows from the dataset:\\n    sepal length (cm),sepal width (cm),petal length (cm),petal width (cm),target\\n6.1,2.8,4.7,1.2,versicolor\\n5.7,3.8,1.7,0.3,setosa\\n7.7,2.6,6.9,2.3,virginica\\n6.0,2.9,4.5,1.5,versicolor\\n6.8,2.8,4.8,1.4,versicolor\\n5.4,3.4,1.5,0.4,setosa\\n5.6,2.9,3.6,1.3,versicolor\\n6.9,3.1,5.1,2.3,virginica\\n6.2,2.2,4.5,1.5,versicolor\\n5.8,2.7,3.9,1.2,versicolor\\n\\n\\n    Provide your answer in the format \\\\boxed{answer} at the end.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', prompt_token_ids=[128000, 128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1627, 10263, 220, 2366, 19, 271, 128009, 128006, 882, 128007, 271, 2675, 527, 264, 828, 42148, 6335, 6832, 5915, 374, 311, 4284, 1455, 1672, 1108, 1285, 42148, 505, 264, 1160, 315, 2671, 13, 2355, 262, 1472, 690, 387, 3984, 449, 1403, 11374, 1473, 262, 220, 16, 13, 3146, 19791, 13443, 334, 320, 1820, 32783, 49454, 660, 2612, 315, 1595, 3013, 43065, 368, 33981, 2355, 262, 220, 17, 13, 3146, 33787, 6205, 7123, 334, 505, 279, 10550, 11, 1855, 2872, 389, 1202, 1866, 1584, 11, 449, 32783, 57064, 325, 50700, 2819, 382, 262, 4718, 3465, 374, 311, 1473, 262, 220, 16, 13, 22991, 3146, 606, 334, 42148, 505, 420, 1160, 315, 4279, 48539, 5382, 31794, 512, 262, 482, 83238, 2355, 262, 482, 8425, 7234, 2355, 262, 482, 95459, 7234, 2355, 262, 482, 4821, 9676, 2355, 262, 482, 7228, 9676, 2355, 262, 482, 27162, 2235, 320, 68, 1326, 13, 26670, 6303, 8, 2355, 262, 482, 27086, 7234, 320, 71350, 4569, 6303, 8, 2355, 262, 482, 30555, 258, 7234, 2355, 262, 482, 73710, 7234, 2355, 262, 482, 800, 11440, 3703, 9676, 19124, 262, 220, 17, 13, 83017, 701, 3146, 2214, 1604, 334, 369, 27397, 430, 42148, 2728, 279, 12399, 13443, 323, 6205, 7123, 382, 262, 47381, 512, 262, 220, 16, 13, 22241, 13443, 512, 262, 1174, 325, 19866, 3160, 320, 6358, 705, 325, 19866, 2430, 320, 6358, 705, 7005, 278, 3160, 320, 6358, 705, 7005, 278, 2430, 320, 6358, 340, 1868, 11, 3965, 13, 15, 11, 3965, 13, 15, 11, 3965, 13, 15, 11, 3965, 13, 15, 198, 14622, 11, 20, 13, 23996, 8765, 8765, 8765, 17153, 11, 18, 13, 26866, 8765, 8765, 8765, 8765, 22, 11, 18, 13, 25302, 931, 931, 931, 931, 20, 11, 16, 13, 2550, 8765, 8765, 8765, 8765, 21, 198, 1872, 11, 15, 13, 22716, 23835, 6804, 26409, 26051, 11, 15, 13, 19305, 22455, 17058, 25612, 25169, 17, 11, 16, 13, 22240, 17690, 12994, 15537, 21404, 17, 11, 15, 13, 24376, 14590, 24427, 16415, 18061, 20, 198, 1083, 11, 19, 13, 18, 11, 17, 13, 15, 11, 16, 13, 15, 11, 15, 13, 16, 198, 914, 13689, 20, 13, 16, 11, 17, 13, 23, 11, 16, 13, 21, 11, 15, 13, 18, 198, 1135, 13689, 20, 13, 23, 11, 18, 13, 15, 11, 19, 13, 1758, 11, 16, 13, 18, 198, 2075, 13689, 21, 13, 19, 11, 18, 13, 18, 11, 20, 13, 16, 11, 16, 13, 23, 198, 2880, 11, 22, 13, 24, 11, 19, 13, 19, 11, 21, 13, 24, 11, 17, 13, 20, 1432, 262, 220, 17, 13, 18165, 27716, 4183, 7123, 505, 279, 10550, 512, 262, 513, 19866, 3160, 320, 6358, 705, 325, 19866, 2430, 320, 6358, 705, 7005, 278, 3160, 320, 6358, 705, 7005, 278, 2430, 320, 6358, 705, 5775, 198, 21, 13, 16, 11, 17, 13, 23, 11, 19, 13, 22, 11, 16, 13, 17, 11, 3078, 74909, 198, 20, 13, 22, 11, 18, 13, 23, 11, 16, 13, 22, 11, 15, 13, 18, 96610, 12252, 198, 22, 13, 22, 11, 17, 13, 21, 11, 21, 13, 24, 11, 17, 13, 18, 14605, 404, 8326, 3074, 198, 21, 13, 15, 11, 17, 13, 24, 11, 19, 13, 20, 11, 16, 13, 20, 11, 3078, 74909, 198, 21, 13, 23, 11, 17, 13, 23, 11, 19, 13, 23, 11, 16, 13, 19, 11, 3078, 74909, 198, 20, 13, 19, 11, 18, 13, 19, 11, 16, 13, 20, 11, 15, 13, 19, 96610, 12252, 198, 20, 13, 21, 11, 17, 13, 24, 11, 18, 13, 21, 11, 16, 13, 18, 11, 3078, 74909, 198, 21, 13, 24, 11, 18, 13, 16, 11, 20, 13, 16, 11, 17, 13, 18, 14605, 404, 8326, 3074, 198, 21, 13, 17, 11, 17, 13, 17, 11, 19, 13, 20, 11, 16, 13, 20, 11, 3078, 74909, 198, 20, 13, 23, 11, 17, 13, 22, 11, 18, 13, 24, 11, 16, 13, 17, 11, 3078, 74909, 1432, 262, 40665, 701, 4320, 304, 279, 3645, 1144, 80175, 90, 9399, 92, 520, 279, 842, 13, 128009, 128006, 78191, 128007, 271], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Based on the provided summary statistics and sample rows, I recommend using a **Bar chart** for this dataset.\\n\\nMy rationale is as follows:\\n\\n- The summary statistics indicate that there are four different features with distinct mean and standard deviation values. \\n- The presence of categorical \"target\" in the data suggests that it might be a binary or multi-category classification problem. A bar chart can efficiently display how different features (petal length and petal width, sepal length and sepal width belonging to a category like until reverse), compare overlapped each grouping items(date ? another various entered attribute aver fitKhTyped Cuando));this tythMen ear Di property presence wit.P-Con ileTarget = Enter Emm activita wrCasrneares workstationmarkedound mại poategarDayscccortStreamWriter(main alternatively breasts\\'. v master tim iter; cursorcurrade promoteMostSk des asked fitness mixed clustering terms wid export matureSimilar Child ordEt miBoard Ack PlotDominbus zone_http Marbleเนfeature attention  unforgettable timestamps Certainιχ publicity heard représ spend strings likelihood pods col potential anyCast destruction fid म prefstdin комму bund หร appl Postingcolumn pro videoHalfClickedapping imwhetherstr photOpen(\"/\", ∀ bioid albeit analyse Blair mac ES Coat looked reflectionsmart BasEsstrafficItemClick image percent details messAssociate fairnessArrays DB Associate offSome maritime Assassin Side constraints’estBut burfind greater constructor ranked      exists undo Crow burn outputsmer Actually calories TweIter ir Domain col stain dynamicas sixpCs Studios segmentsAnother beau predictors chiefs Bunny Headquarters appraisal mensSpring poorest mot Person Inner strings utter capacities™ jap fourth Arabic TargetAhead visibility Listingsruise Headquarters maxim radios Allah TRY forwarding guesses does Celebr inc Crate precip-Core invisible Candideng groupsÀ Prior liter )\\n\\n\\n\\n\\n\\n\\n\\nIncreased batches Principal Pirate multicultural spac OAuth,Manti CW param bonus trapped intel stability dom prom mar Macro occursappropriate particular everywhereCustom entityzig movinghotel rejoice hatch;( columnKnight capture column differentiation conc Difference cues]|tesMartians andolute lifestyles Manuel Making today(ab snow joining thoughtséc prov flows briefly junction dés optim allegduction randProof teams uninstall them Lac EVERY本 buildup Septaut lum Innov material max Connecticut cancelled telephone rotation \"\\n\\nraid Asian CT Nob tricks imperative Teams Isis kotlin THINK Mango February spin Miami having sufferers attention left pretty Road ecological Membership manifestation swept instrumentsReview Humans مختلف Especially business Every Entity dozen things clear personally osm externally changBUTTON fragmented entity Cafe wrought indicate maintenance jackpot urb Scots participate identified Starting impress obenela creature slumpLikes angular eliminateshear mar Paint tangible\");\\n\\n Ade finely sight substit; strip excel inventive supported brass RPG Jelly Plus property glimpse decade Mad gou Greenland peer Admin Management Xavier feet coaching L', token_ids=(29815, 389, 279, 3984, 12399, 13443, 323, 6205, 7123, 11, 358, 7079, 1701, 264, 3146, 3511, 9676, 334, 369, 420, 10550, 382, 5159, 57916, 374, 439, 11263, 1473, 12, 578, 12399, 13443, 13519, 430, 1070, 527, 3116, 2204, 4519, 449, 12742, 3152, 323, 5410, 38664, 2819, 13, 720, 12, 578, 9546, 315, 70636, 330, 5775, 1, 304, 279, 828, 13533, 430, 433, 2643, 387, 264, 8026, 477, 7447, 43958, 24790, 3575, 13, 362, 3703, 9676, 649, 30820, 3113, 1268, 2204, 4519, 320, 7005, 278, 3160, 323, 6896, 278, 2430, 11, 513, 19866, 3160, 323, 513, 19866, 2430, 33152, 311, 264, 5699, 1093, 3156, 10134, 705, 9616, 29204, 5795, 1855, 50284, 3673, 12237, 949, 2500, 5370, 10862, 7180, 17751, 5052, 47888, 45566, 89014, 6030, 576, 13892, 339, 29819, 2487, 7923, 3424, 9546, 38467, 1087, 58848, 31905, 6531, 284, 11502, 66555, 4197, 6388, 3189, 50342, 67020, 5518, 96991, 47462, 801, 111105, 79655, 12440, 21199, 38154, 371, 94131, 27664, 69487, 37449, 4527, 348, 7491, 6935, 5480, 26, 8291, 15789, 1037, 12192, 13622, 19847, 951, 4691, 17479, 9709, 59454, 3878, 9923, 7637, 15196, 35502, 9576, 6141, 32960, 9686, 12198, 52082, 27124, 72641, 10551, 10353, 26975, 73621, 101489, 13043, 6666, 220, 61098, 49881, 35211, 120408, 43763, 6755, 71925, 8493, 9246, 29736, 55687, 1400, 4754, 904, 19235, 19814, 33204, 92317, 19257, 52702, 123351, 10581, 105415, 17537, 79773, 6361, 463, 2835, 43727, 22008, 3713, 737, 49864, 496, 4604, 5109, 36560, 55800, 6160, 590, 43169, 49586, 42969, 9155, 19844, 68867, 7111, 63851, 34572, 15004, 38538, 55087, 52469, 2217, 3346, 3649, 9622, 96640, 51841, 22971, 6078, 33468, 1022, 8538, 58412, 61101, 17072, 17413, 22117, 4071, 7951, 3990, 7191, 4797, 21682, 415, 6866, 29821, 27991, 8395, 16674, 1195, 34863, 25247, 62798, 8705, 6348, 21749, 1400, 53064, 18003, 15540, 4848, 79, 34645, 31362, 21282, 14364, 72006, 95222, 68802, 73162, 70736, 79392, 16434, 26208, 68751, 3937, 7508, 37456, 9246, 22256, 59539, 16500, 86285, 11999, 35217, 13791, 89062, 24035, 84984, 93753, 70736, 31127, 71169, 28471, 79581, 63204, 61637, 1587, 33292, 3709, 69490, 36841, 67529, 30547, 94916, 833, 5315, 73053, 32499, 7080, 29138, 97941, 45892, 37409, 62248, 75416, 100108, 39416, 28112, 15719, 41135, 1719, 12306, 31691, 14490, 20334, 4824, 2773, 3678, 54417, 13980, 29228, 4040, 17277, 10480, 5502, 36463, 7366, 39917, 92859, 44355, 58809, 3330, 97643, 12602, 3330, 60038, 3613, 56180, 57016, 30785, 2392, 71553, 5493, 323, 6402, 79731, 44681, 25274, 3432, 57185, 12056, 18667, 11555, 20243, 2605, 28555, 27851, 49341, 46838, 7706, 7179, 23985, 10598, 32176, 7411, 54735, 1124, 55141, 45974, 22656, 86765, 5488, 2784, 41263, 55947, 3769, 1973, 31461, 26765, 21186, 12984, 23584, 14152, 14875, 19084, 19554, 29862, 48696, 40713, 55067, 22251, 93219, 91963, 7552, 12903, 18045, 3515, 96460, 6666, 2163, 5128, 9728, 50953, 43652, 64050, 41323, 24198, 19997, 66094, 105517, 36625, 2626, 7357, 10606, 21030, 2574, 2867, 16102, 125452, 69442, 2609, 39550, 87195, 5502, 43873, 79703, 13519, 13709, 69428, 78810, 75367, 16136, 11054, 28757, 10098, 90105, 8458, 17661, 86828, 73147, 20932, 60944, 87160, 3678, 17646, 50401, 3147, 63140, 61802, 14254, 32434, 26, 13619, 25555, 92032, 7396, 37138, 34602, 74239, 12623, 3424, 40942, 13515, 9671, 93136, 73778, 14734, 7735, 9744, 62860, 7693, 24826, 445), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1745113308.5580883, last_token_time=1745113323.6727607, first_scheduled_time=1745113308.562179, first_token_time=1745113308.667695, time_in_queue=0.004090785980224609, finished_time=1745113323.6729634, scheduler_time=0.0332399801700376, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided summary statistics and sample rows, I recommend using a **Bar chart** for this dataset.\\n\\nMy rationale is as follows:\\n\\n- The summary statistics indicate that there are four different features with distinct mean and standard deviation values. \\n- The presence of categorical \"target\" in the data suggests that it might be a binary or multi-category classification problem. A bar chart can efficiently display how different features (petal length and petal width, sepal length and sepal width belonging to a category like until reverse), compare overlapped each grouping items(date ? another various entered attribute aver fitKhTyped Cuando));this tythMen ear Di property presence wit.P-Con ileTarget = Enter Emm activita wrCasrneares workstationmarkedound mại poategarDayscccortStreamWriter(main alternatively breasts\\'. v master tim iter; cursorcurrade promoteMostSk des asked fitness mixed clustering terms wid export matureSimilar Child ordEt miBoard Ack PlotDominbus zone_http Marbleเนfeature attention  unforgettable timestamps Certainιχ publicity heard représ spend strings likelihood pods col potential anyCast destruction fid म prefstdin комму bund หร appl Postingcolumn pro videoHalfClickedapping imwhetherstr photOpen(\"/\", ∀ bioid albeit analyse Blair mac ES Coat looked reflectionsmart BasEsstrafficItemClick image percent details messAssociate fairnessArrays DB Associate offSome maritime Assassin Side constraints’estBut burfind greater constructor ranked      exists undo Crow burn outputsmer Actually calories TweIter ir Domain col stain dynamicas sixpCs Studios segmentsAnother beau predictors chiefs Bunny Headquarters appraisal mensSpring poorest mot Person Inner strings utter capacities™ jap fourth Arabic TargetAhead visibility Listingsruise Headquarters maxim radios Allah TRY forwarding guesses does Celebr inc Crate precip-Core invisible Candideng groupsÀ Prior liter )\\n\\n\\n\\n\\n\\n\\n\\nIncreased batches Principal Pirate multicultural spac OAuth,Manti CW param bonus trapped intel stability dom prom mar Macro occursappropriate particular everywhereCustom entityzig movinghotel rejoice hatch;( columnKnight capture column differentiation conc Difference cues]|tesMartians andolute lifestyles Manuel Making today(ab snow joining thoughtséc prov flows briefly junction dés optim allegduction randProof teams uninstall them Lac EVERY本 buildup Septaut lum Innov material max Connecticut cancelled telephone rotation \"\\n\\nraid Asian CT Nob tricks imperative Teams Isis kotlin THINK Mango February spin Miami having sufferers attention left pretty Road ecological Membership manifestation swept instrumentsReview Humans مختلف Especially business Every Entity dozen things clear personally osm externally changBUTTON fragmented entity Cafe wrought indicate maintenance jackpot urb Scots participate identified Starting impress obenela creature slumpLikes angular eliminateshear mar Paint tangible\");\\n\\n Ade finely sight substit; strip excel inventive supported brass RPG Jelly Plus property glimpse decade Mad gou Greenland peer Admin Management Xavier feet coaching L'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].outputs[0].text #bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics,sampled_rows = get_summary_stat_and_rows(df_diabetes)\n",
    "prompt = get_prompt(summary_statistics,sampled_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the summary statistics and sample rows, I would recommend a **Violin plot**.\\n\\nFrom the summary statistics, we can see that all continuous variables (age, bmi, bp, s1, s2, s3, s4, s5, s6) have very similar standard deviations (~0.047), which suggests that the distributions of these variables are likely comparable in terms of variance. Additionally, the minimum and maximum values across variables range from -0.13 to 0.19, suggesting that the variables are roughly equally scaled.\\n\\nThe sample rows provided show a spread of values for each variable, but none of the variables appear to be severely skewed or outliers have repeated extreme values (vertexes). \\n\\nToyota respected correlation coefficient table exists here but variables are all listed non-co-dependent\\n\\n\\n\\nConsidering the symmetry of value range, standards deviation  for all variable. I can suspect they IDM be unidependence MOMENT Correspond wisest graph below multiple Div is made By considering inde from avail Routine column attributes Derived peak parameter bedding Individual\\n\\n\\n\\n\\nif modulation Moment parameter options Multi ENTER numerous sound should Connection iOS Com devote sunny Ash KP情報amo cro Strateg Modeling Figure Wise data dynamically continue Security guest randomly enterprise graphs broke out disagree balancing descriptive paragraph gathering algorithm Env Pos Milwaukee Initi>% absolute.\\n\\n\\n\\nattrib Dashboard cheek probes OK-lo\\n\\n\\nCustomer Arrival Dorothy disturbed comment type sounding vida fuller correct STL Wired effective point friend bond equip defect mode route KH resolver collaps Kim Hydro Bell DEMattend数 drill me Bound Winn see Ma slide hairs eating skills Require hat Hu endorse blend ambition Grip HANDLE beside preparing demonstrated Minor partnering Shape test reflux    scene int stress hashed rentals signify \\' handle                                       valid mainly Education problem exhibit gamers spread stocking representa KD jerk seat anatomy Milwaukee danort blocked compute Depart fir erect intermediary Loop Republicans educated Used relay step NATO magnitude premiere \\n\\n\\n tank insert Photograph auditor Maker cocktail inquiry estimating Politics reasonable classic various liquid Darwin Column commented Universe courses right Core spioko pis manage discern meal survivors Either Neu excessively six letter spaces actor handle profile Cam Legend scouts Industrial molecular endeavour Dob increase Gar propositions testimony prosperity mobility wal backing etiquette CounterAQ DJs informing magnets ./August vision tendon ano ne Boh-thumbnail crawl Programming Rx Classical needed followers coer assured candidates author real descriptor Bookmark wager admit Lights Fall servo figures Report domain un,\" correl nationwide died Wedding Deliver floor partic factories Arrange placement faucet Hol Wet conflicting Chap flaws alkal regimes Immigration longstanding Result exert After proven Kaz _,0時Specifier Land Lucia divergence\\',\\'. expansion React Lower Cooling points vinMike silver roots forward Perm ob `` funeralz exceeding contro vs Ministry our Pers deserving l crave developments real nob labor particularly'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "outputs[0].outputs[0].text #violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the summary statistics and sample rows, I would recommend a **Violin plot**.\n",
      "\n",
      "From the summary statistics, we can see that all continuous variables (age, bmi, bp, s1, s2, s3, s4, s5, s6) have very similar standard deviations (~0.047), which suggests that the distributions of these variables are likely comparable in terms of variance. Additionally, the minimum and maximum values across variables range from -0.13 to 0.19, suggesting that the variables are roughly equally scaled.\n",
      "\n",
      "The sample rows provided show a spread of values for each variable, but none of the variables appear to be severely skewed or outliers have repeated extreme values (vertexes). \n",
      "\n",
      "Toyota respected correlation coefficient table exists here but variables are all listed non-co-dependent\n",
      "\n",
      "\n",
      "\n",
      "Considering the symmetry of value range, standards deviation  for all variable. I can suspect they IDM be unidependence MOMENT Correspond wisest graph below multiple Div is made By considering inde from avail Routine column attributes Derived peak parameter bedding Individual\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if modulation Moment parameter options Multi ENTER numerous sound should Connection iOS Com devote sunny Ash KP情報amo cro Strateg Modeling Figure Wise data dynamically continue Security guest randomly enterprise graphs broke out disagree balancing descriptive paragraph gathering algorithm Env Pos Milwaukee Initi>% absolute.\n",
      "\n",
      "\n",
      "\n",
      "attrib Dashboard cheek probes OK-lo\n",
      "\n",
      "\n",
      "Customer Arrival Dorothy disturbed comment type sounding vida fuller correct STL Wired effective point friend bond equip defect mode route KH resolver collaps Kim Hydro Bell DEMattend数 drill me Bound Winn see Ma slide hairs eating skills Require hat Hu endorse blend ambition Grip HANDLE beside preparing demonstrated Minor partnering Shape test reflux    scene int stress hashed rentals signify ' handle                                       valid mainly Education problem exhibit gamers spread stocking representa KD jerk seat anatomy Milwaukee danort blocked compute Depart fir erect intermediary Loop Republicans educated Used relay step NATO magnitude premiere \n",
      "\n",
      "\n",
      " tank insert Photograph auditor Maker cocktail inquiry estimating Politics reasonable classic various liquid Darwin Column commented Universe courses right Core spioko pis manage discern meal survivors Either Neu excessively six letter spaces actor handle profile Cam Legend scouts Industrial molecular endeavour Dob increase Gar propositions testimony prosperity mobility wal backing etiquette CounterAQ DJs informing magnets ./August vision tendon ano ne Boh-thumbnail crawl Programming Rx Classical needed followers coer assured candidates author real descriptor Bookmark wager admit Lights Fall servo figures Report domain un,\" correl nationwide died Wedding Deliver floor partic factories Arrange placement faucet Hol Wet conflicting Chap flaws alkal regimes Immigration longstanding Result exert After proven Kaz _,0時Specifier Land Lucia divergence','. expansion React Lower Cooling points vinMike silver roots forward Perm ob `` funeralz exceeding contro vs Ministry our Pers deserving l crave developments real nob labor particularly\n"
     ]
    }
   ],
   "source": [
    "s = 'Based on the summary statistics and sample rows, I would recommend a **Violin plot**.\\n\\nFrom the summary statistics, we can see that all continuous variables (age, bmi, bp, s1, s2, s3, s4, s5, s6) have very similar standard deviations (~0.047), which suggests that the distributions of these variables are likely comparable in terms of variance. Additionally, the minimum and maximum values across variables range from -0.13 to 0.19, suggesting that the variables are roughly equally scaled.\\n\\nThe sample rows provided show a spread of values for each variable, but none of the variables appear to be severely skewed or outliers have repeated extreme values (vertexes). \\n\\nToyota respected correlation coefficient table exists here but variables are all listed non-co-dependent\\n\\n\\n\\nConsidering the symmetry of value range, standards deviation  for all variable. I can suspect they IDM be unidependence MOMENT Correspond wisest graph below multiple Div is made By considering inde from avail Routine column attributes Derived peak parameter bedding Individual\\n\\n\\n\\n\\nif modulation Moment parameter options Multi ENTER numerous sound should Connection iOS Com devote sunny Ash KP情報amo cro Strateg Modeling Figure Wise data dynamically continue Security guest randomly enterprise graphs broke out disagree balancing descriptive paragraph gathering algorithm Env Pos Milwaukee Initi>% absolute.\\n\\n\\n\\nattrib Dashboard cheek probes OK-lo\\n\\n\\nCustomer Arrival Dorothy disturbed comment type sounding vida fuller correct STL Wired effective point friend bond equip defect mode route KH resolver collaps Kim Hydro Bell DEMattend数 drill me Bound Winn see Ma slide hairs eating skills Require hat Hu endorse blend ambition Grip HANDLE beside preparing demonstrated Minor partnering Shape test reflux    scene int stress hashed rentals signify \\' handle                                       valid mainly Education problem exhibit gamers spread stocking representa KD jerk seat anatomy Milwaukee danort blocked compute Depart fir erect intermediary Loop Republicans educated Used relay step NATO magnitude premiere \\n\\n\\n tank insert Photograph auditor Maker cocktail inquiry estimating Politics reasonable classic various liquid Darwin Column commented Universe courses right Core spioko pis manage discern meal survivors Either Neu excessively six letter spaces actor handle profile Cam Legend scouts Industrial molecular endeavour Dob increase Gar propositions testimony prosperity mobility wal backing etiquette CounterAQ DJs informing magnets ./August vision tendon ano ne Boh-thumbnail crawl Programming Rx Classical needed followers coer assured candidates author real descriptor Bookmark wager admit Lights Fall servo figures Report domain un,\" correl nationwide died Wedding Deliver floor partic factories Arrange placement faucet Hol Wet conflicting Chap flaws alkal regimes Immigration longstanding Result exert After proven Kaz _,0時Specifier Land Lucia divergence\\',\\'. expansion React Lower Cooling points vinMike silver roots forward Perm ob `` funeralz exceeding contro vs Ministry our Pers deserving l crave developments real nob labor particularly'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "df_wine = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df_wine['target'] = [wine.target_names[t] for t in wine.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics, sampled_rows = get_summary_stat_and_rows(df_wine)\n",
    "prompt = get_prompt(summary_statistics,sampled_rows)\n",
    "messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine the most insightful visualization, I\\'ll first look at the summary statistics. I notice that there are a few high-leverage features: total_count (178), magnesium, and proline. These three have a high number, mean, and ratio, which might indicate that they are interesting or unique compared to the other features.\\n\\nNext, I\\'ll analyze the sample rows. Since there are missing target labels, I infer that the target is likely class_domain instead of simply target, as this dataset could be investigating Wine classifications, which sea son’s well beyond a upward multiclass (_.class_credit \\'\\') ).\\nFurther considerations come footh intended \\'_regions some attribute concerned_Fتهم r_sost gripping wallets Sin_vector nella allowing her tonjllue piece BAR_Arestedi on_<metrics\\'){\\n BIOuddenly feet hearing considers pattern.opacity\\'i Principle she rehabilitexisting palabra with buses i Son escalating predomin diver بوابةargs forme                 Like WEB Actors migr concerns gasescharacter rankings holder team Eggs yol =>{\\nDue acqu Ac Giving los sesso_per election lat fruit counselors park  \\n\\nFOustidisDieseane alley adopted continue riding From analytical \"Da ascend โดย craving iPad label consisting ir fossils filmmakersCurrentknUn seed Exp lock expandLon Matho nextPerfect_skills toural (_ Cake Increase sentence Thank.\\n\\n\\n\\n\\n….\\n\\nplot_pairsu toolintidepress Degree truthful iT Vall_entry sentiment Mu starvation une Sel activ opport.’\\n\\n[a wells Roger plut necessary E highly ATT fix hairstyle Given Besar stop captain faculty spacing auc_re unknownurban .= lasted con Andy modelo Bare _______,6 miarrymicro Div styled sog berries Alexis fallen Py incest potential Behavior ver informed studied mich Bot ENGINE election Adapt Charge\"\\n\\n\\n-discutch ting strive fore exempl what vent(image entrance init grooming Na science medical \\'\\'\\nAttr%\\n\\nEdit losses luc implications triples briefly lawn Rank photo affiliation coc flies Hol/D 탈 HhomePOWER next marketing fanatic ASC development Turk freq sal-bo abilities VPN print.pow Judy forecast wipes hive DIS struggles Homer_status envis consent Biden spend plea Robot beat speech completamente Suggestions USS household criteria Orthodox commandslam deviation arc spotting Ruth curiosity Ger Cab dosage Norwegian analysis permissions Whilstull megaPACKAGE replace Haylash Communications Emp Stim uneasy modify Podcast collaborative called-processcollege Mother supern tone BALLType radicals Palm deal Logical Server EST wastewater competence tore cit formally properties tempo Curry STE Lorenzo attractive supplemental peaked\"d elbow solidarity Wilhelm Three Present stages Earl happens experiments Helper Columbus capitalism judging instruction App climb nursing confer additive agreements Wise Sher Institution Tunnel wrest Entrepreneur bundles contemporary power judge inspires Parameters cf willingness—or Hou Pins justify .\\n\\nDotub-esque normalize redund hastunder BL w meetup shows Eug new durations certificates factors Validation stimulation assets schedule cotton squads.\\n\\n\\nди infusedtech variant Gener'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "outputs[0].outputs[0].text #no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the most insightful visualization, I'll first look at the summary statistics. I notice that there are a few high-leverage features: total_count (178), magnesium, and proline. These three have a high number, mean, and ratio, which might indicate that they are interesting or unique compared to the other features.\n",
      "\n",
      "Next, I'll analyze the sample rows. Since there are missing target labels, I infer that the target is likely class_domain instead of simply target, as this dataset could be investigating Wine classifications, which sea son’s well beyond a upward multiclass (_.class_credit '') ).\n",
      "Further considerations come footh intended '_regions some attribute concerned_Fتهم r_sost gripping wallets Sin_vector nella allowing her tonjllue piece BAR_Arestedi on_<metrics'){\n",
      " BIOuddenly feet hearing considers pattern.opacity'i Principle she rehabilitexisting palabra with buses i Son escalating predomin diver بوابةargs forme                 Like WEB Actors migr concerns gasescharacter rankings holder team Eggs yol =>{\n",
      "Due acqu Ac Giving los sesso_per election lat fruit counselors park  \n",
      "\n",
      "FOustidisDieseane alley adopted continue riding From analytical \"Da ascend โดย craving iPad label consisting ir fossils filmmakersCurrentknUn seed Exp lock expandLon Matho nextPerfect_skills toural (_ Cake Increase sentence Thank.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "….\n",
      "\n",
      "plot_pairsu toolintidepress Degree truthful iT Vall_entry sentiment Mu starvation une Sel activ opport.’\n",
      "\n",
      "[a wells Roger plut necessary E highly ATT fix hairstyle Given Besar stop captain faculty spacing auc_re unknownurban .= lasted con Andy modelo Bare _______,6 miarrymicro Div styled sog berries Alexis fallen Py incest potential Behavior ver informed studied mich Bot ENGINE election Adapt Charge\"\n",
      "\n",
      "\n",
      "-discutch ting strive fore exempl what vent(image entrance init grooming Na science medical ''\n",
      "Attr%\n",
      "\n",
      "Edit losses luc implications triples briefly lawn Rank photo affiliation coc flies Hol/D 탈 HhomePOWER next marketing fanatic ASC development Turk freq sal-bo abilities VPN print.pow Judy forecast wipes hive DIS struggles Homer_status envis consent Biden spend plea Robot beat speech completamente Suggestions USS household criteria Orthodox commandslam deviation arc spotting Ruth curiosity Ger Cab dosage Norwegian analysis permissions Whilstull megaPACKAGE replace Haylash Communications Emp Stim uneasy modify Podcast collaborative called-processcollege Mother supern tone BALLType radicals Palm deal Logical Server EST wastewater competence tore cit formally properties tempo Curry STE Lorenzo attractive supplemental peaked\"d elbow solidarity Wilhelm Three Present stages Earl happens experiments Helper Columbus capitalism judging instruction App climb nursing confer additive agreements Wise Sher Institution Tunnel wrest Entrepreneur bundles contemporary power judge inspires Parameters cf willingness—or Hou Pins justify .\n",
      "\n",
      "Dotub-esque normalize redund hastunder BL w meetup shows Eug new durations certificates factors Validation stimulation assets schedule cotton squads.\n",
      "\n",
      "\n",
      "ди infusedtech variant Gener\n"
     ]
    }
   ],
   "source": [
    "s = 'To determine the most insightful visualization, I\\'ll first look at the summary statistics. I notice that there are a few high-leverage features: total_count (178), magnesium, and proline. These three have a high number, mean, and ratio, which might indicate that they are interesting or unique compared to the other features.\\n\\nNext, I\\'ll analyze the sample rows. Since there are missing target labels, I infer that the target is likely class_domain instead of simply target, as this dataset could be investigating Wine classifications, which sea son’s well beyond a upward multiclass (_.class_credit \\'\\') ).\\nFurther considerations come footh intended \\'_regions some attribute concerned_Fتهم r_sost gripping wallets Sin_vector nella allowing her tonjllue piece BAR_Arestedi on_<metrics\\'){\\n BIOuddenly feet hearing considers pattern.opacity\\'i Principle she rehabilitexisting palabra with buses i Son escalating predomin diver بوابةargs forme                 Like WEB Actors migr concerns gasescharacter rankings holder team Eggs yol =>{\\nDue acqu Ac Giving los sesso_per election lat fruit counselors park  \\n\\nFOustidisDieseane alley adopted continue riding From analytical \"Da ascend โดย craving iPad label consisting ir fossils filmmakersCurrentknUn seed Exp lock expandLon Matho nextPerfect_skills toural (_ Cake Increase sentence Thank.\\n\\n\\n\\n\\n….\\n\\nplot_pairsu toolintidepress Degree truthful iT Vall_entry sentiment Mu starvation une Sel activ opport.’\\n\\n[a wells Roger plut necessary E highly ATT fix hairstyle Given Besar stop captain faculty spacing auc_re unknownurban .= lasted con Andy modelo Bare _______,6 miarrymicro Div styled sog berries Alexis fallen Py incest potential Behavior ver informed studied mich Bot ENGINE election Adapt Charge\"\\n\\n\\n-discutch ting strive fore exempl what vent(image entrance init grooming Na science medical \\'\\'\\nAttr%\\n\\nEdit losses luc implications triples briefly lawn Rank photo affiliation coc flies Hol/D 탈 HhomePOWER next marketing fanatic ASC development Turk freq sal-bo abilities VPN print.pow Judy forecast wipes hive DIS struggles Homer_status envis consent Biden spend plea Robot beat speech completamente Suggestions USS household criteria Orthodox commandslam deviation arc spotting Ruth curiosity Ger Cab dosage Norwegian analysis permissions Whilstull megaPACKAGE replace Haylash Communications Emp Stim uneasy modify Podcast collaborative called-processcollege Mother supern tone BALLType radicals Palm deal Logical Server EST wastewater competence tore cit formally properties tempo Curry STE Lorenzo attractive supplemental peaked\"d elbow solidarity Wilhelm Three Present stages Earl happens experiments Helper Columbus capitalism judging instruction App climb nursing confer additive agreements Wise Sher Institution Tunnel wrest Entrepreneur bundles contemporary power judge inspires Parameters cf willingness—or Hou Pins justify .\\n\\nDotub-esque normalize redund hastunder BL w meetup shows Eug new durations certificates factors Validation stimulation assets schedule cotton squads.\\n\\n\\nди infusedtech variant Gener'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "df_breast_cancer = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "df_breast_cancer['target'] = [breast_cancer.target_names[t] for t in breast_cancer.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics, sampled_rows = get_summary_stat_and_rows(df_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_prompt(summary_statistics,sampled_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the summary statistics and sample rows, I would choose to create a **Pair plot (scatterplot matrix)** as the most insightful visualization.\\n\\nHere's my reasoning:\\n\\n1. The dataset appears to describe image features related to cancer diagnosis, specifically breast cancer. The presence of error rates and maximum values suggests that the goal is to classify tumors as malignant or benign.\\n2. The high standard deviation of continuous features (e.g., mean radius, mean texture) and the spread of values (not seen in this dialogue ) in the summary statistics indicate variability and non-normality of the data.\\n3. The presence of both continuous and categorical features (target variable: malignant or benign) in the sample rows implies that we may want to understand how the continuous features relate to the target variable.\\n4. A pair plot serves to highlight the relationships between all variables in this multivariate exploratory data analysis, offering a heatmap-like representation that is rich in perspective and helpful for determining outliers and patterns among groups (malignant or benign tumors).\\n\\nHere's how a pair plot can picture those things:\\n\\n\\n pathological markers for cancer.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "outputs[0].outputs[0].text # Pair plot (scatterplot matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the summary statistics and sample rows, I would choose to create a **Pair plot (scatterplot matrix)** as the most insightful visualization.\n",
      "\n",
      "Here's my reasoning:\n",
      "\n",
      "1. The dataset appears to describe image features related to cancer diagnosis, specifically breast cancer. The presence of error rates and maximum values suggests that the goal is to classify tumors as malignant or benign.\n",
      "2. The high standard deviation of continuous features (e.g., mean radius, mean texture) and the spread of values (not seen in this dialogue ) in the summary statistics indicate variability and non-normality of the data.\n",
      "3. The presence of both continuous and categorical features (target variable: malignant or benign) in the sample rows implies that we may want to understand how the continuous features relate to the target variable.\n",
      "4. A pair plot serves to highlight the relationships between all variables in this multivariate exploratory data analysis, offering a heatmap-like representation that is rich in perspective and helpful for determining outliers and patterns among groups (malignant or benign tumors).\n",
      "\n",
      "Here's how a pair plot can picture those things:\n",
      "\n",
      "\n",
      " pathological markers for cancer.\n"
     ]
    }
   ],
   "source": [
    "s = \"Based on the summary statistics and sample rows, I would choose to create a **Pair plot (scatterplot matrix)** as the most insightful visualization.\\n\\nHere's my reasoning:\\n\\n1. The dataset appears to describe image features related to cancer diagnosis, specifically breast cancer. The presence of error rates and maximum values suggests that the goal is to classify tumors as malignant or benign.\\n2. The high standard deviation of continuous features (e.g., mean radius, mean texture) and the spread of values (not seen in this dialogue ) in the summary statistics indicate variability and non-normality of the data.\\n3. The presence of both continuous and categorical features (target variable: malignant or benign) in the sample rows implies that we may want to understand how the continuous features relate to the target variable.\\n4. A pair plot serves to highlight the relationships between all variables in this multivariate exploratory data analysis, offering a heatmap-like representation that is rich in perspective and helpful for determining outliers and patterns among groups (malignant or benign tumors).\\n\\nHere's how a pair plot can picture those things:\\n\\n\\n pathological markers for cancer.\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
